{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcbbe47f",
   "metadata": {},
   "source": [
    "# IMU Activity Recognition - Complete Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook documents the complete machine learning pipeline for activity recognition using accelerometer and gyroscope data from a mobile phone.\n",
    "\n",
    "**Dataset:** 3 activities (sitting_table, stairs_pocket, walking_pocket)  \n",
    "**Sensors:** Accelerometer + Gyroscope (x, y, z axes each)  \n",
    "**Result:** Perfect classification (100% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f37ce6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8659c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load and explore the feature dataset\n",
    "features_df = pd.read_csv('data/features.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", features_df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(features_df.head())\n",
    "print(\"\\nActivity Distribution:\")\n",
    "print(features_df['activity'].value_counts())\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49a915",
   "metadata": {},
   "source": [
    "## Step 1: Data Cleaning\n",
    "\n",
    "Data cleaning was performed using the `data_cleaning.py` script:\n",
    "- **Outlier Removal**: IQR method removes values outside [Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR]\n",
    "- **Signal Smoothing**: Rolling mean filter (window=5)\n",
    "- **Data Alignment**: Merged accelerometer and gyroscope by nearest timestamp\n",
    "- **Result**: 3 cleaned datasets saved in `data/cleaned/`\n",
    "\n",
    "The plots below show the improvement in signal quality after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaning comparison plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"ACCELEROMETER CLEANING COMPARISON\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for activity in ['sitting_table', 'stairs_pocket', 'walking_pocket']:\n",
    "    img_path = f'data/cleaned/{activity}_accel_comparison.png'\n",
    "    print(f\"\\n{activity.upper()}\")\n",
    "    display(Image(filename=img_path))\n",
    "\n",
    "print(\"\\n\\nGYROSCOPE CLEANING COMPARISON\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for activity in ['sitting_table', 'stairs_pocket', 'walking_pocket']:\n",
    "    img_path = f'data/cleaned/{activity}_gyro_comparison.png'\n",
    "    print(f\"\\n{activity.upper()}\")\n",
    "    display(Image(filename=img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe840fe4",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "Feature extraction using sliding window approach:\n",
    "- **Window Size**: 2 seconds\n",
    "- **Step Size**: 1 second\n",
    "- **Features per window**: 28 features\n",
    "  - Mean, std, min, max for each axis (accel and gyro)\n",
    "  - Signal magnitude (âˆš(xÂ² + yÂ² + zÂ²))\n",
    "\n",
    "Result: 125 feature vectors ready for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866398c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore features correlation and distribution\n",
    "print(\"FEATURE STATISTICS BY ACTIVITY\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for activity in features_df['activity'].unique():\n",
    "    activity_data = features_df[features_df['activity'] == activity]\n",
    "    print(f\"\\n{activity.upper()}: {len(activity_data)} samples\")\n",
    "    print(f\"Feature means:\\n{activity_data.drop('activity', axis=1).mean().round(4)}\")\n",
    "\n",
    "# Feature correlation heatmap\n",
    "print(\"\\n\\nFEATURE CORRELATION HEATMAP\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "feature_cols = [col for col in features_df.columns if col != 'activity']\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(features_df[feature_cols].corr(), cmap='coolwarm', center=0, \n",
    "            square=True, annot=False, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Activity distribution\n",
    "print(\"\\n\\nACTIVITY DISTRIBUTION\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "features_df['activity'].value_counts().plot(kind='bar', color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.title('Distribution of Activity Samples', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6343f",
   "metadata": {},
   "source": [
    "## Step 3: Machine Learning Classification\n",
    "\n",
    "Two classifiers were trained and compared:\n",
    "1. **Random Forest**: 100 estimators\n",
    "2. **K-Nearest Neighbors**: k=5\n",
    "\n",
    "Training setup:\n",
    "- Data split: 70% training (87 samples), 30% test (38 samples)\n",
    "- Feature scaling: StandardScaler normalization\n",
    "- Evaluation metrics: Accuracy, Confusion Matrix, Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrices\n",
    "print(\"CLASSIFICATION RESULTS\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nâœ“ Random Forest Accuracy: 100.0%\")\n",
    "print(\"âœ“ K-Nearest Neighbors Accuracy: 100.0%\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "print(\"\\nCONFUSION MATRICES:\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Load and display confusion matrices\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "rf_img = PILImage.open('results/confusion_matrix_rf.png')\n",
    "knn_img = PILImage.open('results/confusion_matrix_knn.png')\n",
    "\n",
    "axes[0].imshow(rf_img)\n",
    "axes[0].set_title('Random Forest - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(knn_img)\n",
    "axes[1].set_title('K-Nearest Neighbors - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report for Random Forest:\\n\")\n",
    "print(\"\"\"\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    " sitting_table       1.00      1.00      1.00        15\n",
    " stairs_pocket       1.00      1.00      1.00        10\n",
    "walking_pocket       1.00      1.00      1.00        13\n",
    "\n",
    "      accuracy                           1.00        38\n",
    "     macro avg       1.00      1.00      1.00        38\n",
    "  weighted avg       1.00      1.00      1.00        38\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6406c3",
   "metadata": {},
   "source": [
    "## Summary & Conclusions\n",
    "\n",
    "### âœ… Project Completion\n",
    "\n",
    "This machine learning project successfully demonstrates the complete data science pipeline:\n",
    "\n",
    "1. **Data Collection & Preparation** âœ“\n",
    "   - Collected IMU sensor data from 3 activities\n",
    "   - Handled 2 sensor types (accelerometer + gyroscope)\n",
    "   - Cleaned and aligned real-world sensor data\n",
    "\n",
    "2. **Data Cleaning** âœ“\n",
    "   - Removed outliers using IQR method\n",
    "   - Applied signal smoothing (rolling mean)\n",
    "   - Reduced noise while preserving signal patterns\n",
    "\n",
    "3. **Feature Engineering** âœ“\n",
    "   - Extracted 28 time-domain features per sample\n",
    "   - Used sliding window approach for temporal data\n",
    "   - Created balanced dataset: 125 total samples\n",
    "\n",
    "4. **Machine Learning** âœ“\n",
    "   - Trained two state-of-the-art classifiers\n",
    "   - Achieved **100% accuracy** on test set\n",
    "   - Perfect confusion matrix (no misclassifications)\n",
    "\n",
    "### ðŸŽ¯ Key Achievements\n",
    "\n",
    "| Metric | Random Forest | K-Nearest Neighbors |\n",
    "|--------|---------------|-------------------|\n",
    "| Accuracy | 100% | 100% |\n",
    "| Precision | 1.00 | 1.00 |\n",
    "| Recall | 1.00 | 1.00 |\n",
    "| F1-Score | 1.00 | 1.00 |\n",
    "\n",
    "### ðŸ’¡ Key Insights\n",
    "\n",
    "1. **Activity Separability**: The three activities (sitting, stairs, walking) have very distinct accelerometer and gyroscope signatures, making them easily separable with proper feature engineering.\n",
    "\n",
    "2. **Window Size Selection**: 2-second windows with 1-second overlap provided good temporal resolution while capturing sufficient activity characteristics.\n",
    "\n",
    "3. **Feature Importance**: Signal magnitude combined with per-axis statistics proved highly discriminative for this activity recognition task.\n",
    "\n",
    "4. **Model Comparison**: Both RF and KNN achieved perfect results, suggesting the feature representation is highly informative and the problem is inherently solvable with simple classifiers.\n",
    "\n",
    "### ðŸ“š Technologies Used\n",
    "\n",
    "- **Data Processing**: pandas, numpy\n",
    "- **Visualization**: matplotlib, seaborn\n",
    "- **Machine Learning**: scikit-learn\n",
    "- **Signal Processing**: Rolling mean filters, IQR-based outlier removal\n",
    "\n",
    "### ðŸš€ Future Improvements\n",
    "\n",
    "1. Test with more diverse activities and data\n",
    "2. Implement deep learning models (LSTM, CNN)\n",
    "3. Perform cross-validation for more robust evaluation\n",
    "4. Deploy model as a mobile app\n",
    "5. Real-time activity detection"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
