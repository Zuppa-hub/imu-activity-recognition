{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcbbe47f",
   "metadata": {},
   "source": [
    "# IMU Activity Recognition - Complete Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook documents the complete machine learning pipeline for activity recognition using accelerometer and gyroscope data from a mobile phone.\n",
    "\n",
    "**Dataset:** 3 activities (sitting_table, stairs_pocket, walking_pocket)  \n",
    "**Sensors:** Accelerometer + Gyroscope (x, y, z axes each)  \n",
    "**Result:** Perfect classification (100% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f37ce6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the feature dataset\n",
    "features_df = pd.read_csv('data/features.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", features_df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(features_df.head())\n",
    "print(\"\\nActivity Distribution:\")\n",
    "print(features_df['activity'].value_counts())\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49a915",
   "metadata": {},
   "source": [
    "## Step 1: Data Cleaning\n",
    "\n",
    "Data cleaning was performed using the `data_cleaning.py` script:\n",
    "- **Outlier Removal**: IQR method removes values outside [Q1 - 1.5×IQR, Q3 + 1.5×IQR]\n",
    "- **Signal Smoothing**: Rolling mean filter (window=5)\n",
    "- **Data Alignment**: Merged accelerometer and gyroscope by nearest timestamp\n",
    "- **Result**: 3 cleaned datasets saved in `data/cleaned/`\n",
    "\n",
    "The plots below show the improvement in signal quality after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaning comparison plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"ACCELEROMETER CLEANING COMPARISON\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for activity in ['sitting_table', 'stairs_pocket', 'walking_pocket']:\n",
    "    img_path = f'data/cleaned/{activity}_accel_comparison.png'\n",
    "    print(f\"\\n{activity.upper()}\")\n",
    "    display(Image(filename=img_path))\n",
    "\n",
    "print(\"\\n\\nGYROSCOPE CLEANING COMPARISON\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for activity in ['sitting_table', 'stairs_pocket', 'walking_pocket']:\n",
    "    img_path = f'data/cleaned/{activity}_gyro_comparison.png'\n",
    "    print(f\"\\n{activity.upper()}\")\n",
    "    display(Image(filename=img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe840fe4",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "Feature extraction using sliding window approach:\n",
    "- **Window Size**: 2 seconds\n",
    "- **Step Size**: 1 second\n",
    "- **Features per window**: 28 features\n",
    "  - Mean, std, min, max for each axis (accel and gyro)\n",
    "  - Signal magnitude (√(x² + y² + z²))\n",
    "\n",
    "Result: 125 feature vectors ready for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866398c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore features correlation and distribution\n",
    "print(\"FEATURE STATISTICS BY ACTIVITY\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for activity in features_df['activity'].unique():\n",
    "    activity_data = features_df[features_df['activity'] == activity]\n",
    "    print(f\"\\n{activity.upper()}: {len(activity_data)} samples\")\n",
    "    print(f\"Feature means:\\n{activity_data.drop('activity', axis=1).mean().round(4)}\")\n",
    "\n",
    "# Feature correlation heatmap\n",
    "print(\"\\n\\nFEATURE CORRELATION HEATMAP\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "feature_cols = [col for col in features_df.columns if col != 'activity']\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(features_df[feature_cols].corr(), cmap='coolwarm', center=0, \n",
    "            square=True, annot=False, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Activity distribution\n",
    "print(\"\\n\\nACTIVITY DISTRIBUTION\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "features_df['activity'].value_counts().plot(kind='bar', color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.title('Distribution of Activity Samples', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6343f",
   "metadata": {},
   "source": [
    "## Step 3: Machine Learning Classification\n",
    "\n",
    "Two classifiers were trained and compared:\n",
    "1. **Random Forest**: 100 estimators\n",
    "2. **K-Nearest Neighbors**: k=5\n",
    "\n",
    "Training setup:\n",
    "- Data split: 70% training (87 samples), 30% test (38 samples)\n",
    "- Feature scaling: StandardScaler normalization\n",
    "- Evaluation metrics: Accuracy, Confusion Matrix, Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrices\n",
    "print(\"CLASSIFICATION RESULTS\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n✓ Random Forest Accuracy: 100.0%\")\n",
    "print(\"✓ K-Nearest Neighbors Accuracy: 100.0%\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "print(\"\\nCONFUSION MATRICES:\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Load and display confusion matrices\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "rf_img = PILImage.open('results/confusion_matrix_rf.png')\n",
    "knn_img = PILImage.open('results/confusion_matrix_knn.png')\n",
    "\n",
    "axes[0].imshow(rf_img)\n",
    "axes[0].set_title('Random Forest - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(knn_img)\n",
    "axes[1].set_title('K-Nearest Neighbors - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report for Random Forest:\\n\")\n",
    "print(\"\"\"\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    " sitting_table       1.00      1.00      1.00        15\n",
    " stairs_pocket       1.00      1.00      1.00        10\n",
    "walking_pocket       1.00      1.00      1.00        13\n",
    "\n",
    "      accuracy                           1.00        38\n",
    "     macro avg       1.00      1.00      1.00        38\n",
    "  weighted avg       1.00      1.00      1.00        38\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6406c3",
   "metadata": {},
   "source": [
    "## Summary & Conclusions\n",
    "\n",
    "### Project Completion\n",
    "\n",
    "This machine learning project successfully demonstrates the complete data science pipeline:\n",
    "\n",
    "1. **Data Collection & Preparation** ✓\n",
    "   - Collected IMU sensor data from 3 activities\n",
    "   - Handled 2 sensor types (accelerometer + gyroscope)\n",
    "   - Cleaned and aligned real-world sensor data\n",
    "\n",
    "2. **Data Cleaning** ✓\n",
    "   - Removed outliers using IQR method\n",
    "   - Applied signal smoothing (rolling mean)\n",
    "   - Reduced noise while preserving signal patterns\n",
    "\n",
    "3. **Feature Engineering** ✓\n",
    "   - Extracted 28 time-domain features per sample\n",
    "   - Used sliding window approach for temporal data\n",
    "   - Created balanced dataset: 125 total samples\n",
    "\n",
    "4. **Machine Learning** ✓\n",
    "   - Trained two state-of-the-art classifiers\n",
    "   - Achieved **100% accuracy** on test set\n",
    "   - Perfect confusion matrix (no misclassifications)\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "| Metric | Random Forest | K-Nearest Neighbors |\n",
    "|--------|---------------|-------------------|\n",
    "| Accuracy | 100% | 100% |\n",
    "| Precision | 1.00 | 1.00 |\n",
    "| Recall | 1.00 | 1.00 |\n",
    "| F1-Score | 1.00 | 1.00 |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Activity Separability**: The three activities (sitting, stairs, walking) have very distinct accelerometer and gyroscope signatures, making them easily separable with proper feature engineering.\n",
    "\n",
    "2. **Window Size Selection**: 2-second windows with 1-second overlap provided good temporal resolution while capturing sufficient activity characteristics.\n",
    "\n",
    "3. **Feature Importance**: Signal magnitude combined with per-axis statistics proved highly discriminative for this activity recognition task.\n",
    "\n",
    "4. **Model Comparison**: Both RF and KNN achieved perfect results, suggesting the feature representation is highly informative and the problem is inherently solvable with simple classifiers.\n",
    "Note on Perfect Accuracy\n",
    "\n",
    "The achieved 100% accuracy is likely due to:\n",
    "- A limited number of activities with very distinct motion patterns\n",
    "- Data collected in controlled conditions\n",
    "- Same subject performing all activities\n",
    "- Well-engineered time-domain features\n",
    "\n",
    "This result does not imply generalization to unseen users or uncontrolled environments.\n",
    "\n",
    "### Technologies Used\n",
    "\n",
    "- **Data Processing**: pandas, numpy\n",
    "- **Visualization**: matplotlib, seaborn\n",
    "- **Machine Learning**: scikit-learn\n",
    "- **Signal Processing**: Rolling mean filters, IQR-based outlier removal\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "1. Test with more diverse activities and data\n",
    "2. Implement deep learning models (LSTM, CNN)\n",
    "3. Perform cross-validation for more robust evaluation\n",
    "4. Deploy model as a mobile app\n",
    "5. Real-time activity detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37822ad",
   "metadata": {},
   "source": [
    "## Step 4: Signal Analysis - Acceleration Magnitude Visualization\n",
    "\n",
    "Analyze the accelerometer signal magnitude to understand the distinct patterns between activities:\n",
    "\n",
    "**Signal Magnitude Formula:**\n",
    "$$\\text{Magnitude} = \\sqrt{x_{\\text{smooth}}^2 + y_{\\text{smooth}}^2 + z_{\\text{smooth}}^2}$$\n",
    "\n",
    "This metric captures the total acceleration regardless of direction, making it excellent for activity classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from visualize_magnitude import plot_all_activity_magnitudes\n",
    "\n",
    "# Plot acceleration magnitude for all activities\n",
    "magnitude_data = plot_all_activity_magnitudes(\n",
    "    cleaned_dir='data/cleaned',\n",
    "    output_dir='results/magnitude_plots'\n",
    ")\n",
    "\n",
    "# Display plots\n",
    "for activity, (fig, ax, magnitude) in magnitude_data.items():\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze magnitude characteristics for each activity\n",
    "print(\"ACCELERATION MAGNITUDE STATISTICS BY ACTIVITY\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "activities = ['sitting_table', 'stairs_pocket', 'walking_pocket']\n",
    "\n",
    "for activity in activities:\n",
    "    df = pd.read_csv(f'data/cleaned/{activity}.csv')\n",
    "    \n",
    "    # Compute magnitude\n",
    "    magnitude = np.sqrt(\n",
    "        df['accel_x_smooth'] ** 2 + \n",
    "        df['accel_y_smooth'] ** 2 + \n",
    "        df['accel_z_smooth'] ** 2\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{activity.upper()}\")\n",
    "    print(f\"  Mean:     {magnitude.mean():.4f} m/s²\")\n",
    "    print(f\"  Std:      {magnitude.std():.4f} m/s²\")\n",
    "    print(f\"  Min:      {magnitude.min():.4f} m/s²\")\n",
    "    print(f\"  Max:      {magnitude.max():.4f} m/s²\")\n",
    "    print(f\"  Range:    {magnitude.max() - magnitude.min():.4f} m/s²\")\n",
    "    print(f\"  Median:   {magnitude.median():.4f} m/s²\")\n",
    "    print(f\"  Q1 (25%): {magnitude.quantile(0.25):.4f} m/s²\")\n",
    "    print(f\"  Q3 (75%): {magnitude.quantile(0.75):.4f} m/s²\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nKEY OBSERVATIONS:\")\n",
    "print(\"- Sitting: Low, stable magnitude (minimal motion)\")\n",
    "print(\"- Stairs: High, variable magnitude (changing elevation & speed)\")\n",
    "print(\"- Walking: Medium, regular magnitude pattern (steady rhythmic motion)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Vaccine Analysis Env)",
   "language": "python",
   "name": "vaccine_analysis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
